p8105_hw3_yc4584
================
Yingyu Cui
2024-10-08

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(ggridges)
library(patchwork)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Problem 1

``` r
library(p8105.datasets)
data("ny_noaa")
```

``` r
na_counts = colSums(is.na(ny_noaa))

print(na_counts)
```

    ##      id    date    prcp    snow    snwd    tmax    tmin 
    ##       0       0  145838  381221  591786 1134358 1134420

- A short discription: This dataset contains 2595176 rows and 7 columns.
  The data frame contains the information of the weather in New York
  from January 1, 1981 through December 31, 2010. The key variables are
  “date”, “temperature_min”, “temperature_max”, “precipitation”,
  “snowfall”, “snow_depth”. In all of the variables, the “prcp”, “snow”
  and “snwd” variables are numeric variables and the “tmax”, “tmin” and
  “id” are recognized as character variables. However, I would prefer to
  transfer “tman” and “tmin” into numeric characters. The missing data
  in every column is shown in the following table. id date prcp snow
  snwd tmax tmin 0 0 145838 381221 591786 1134358 1134420 We can see
  that there are around half of the data missing in the “tmax” and
  “tmin” columns. In “prcp”, “snow” and “snwd” columns, there are less
  data missing, but still a large amount of data missing.

Question 1: - Create separate variables for year, month, and day

``` r
ny_noaa = ny_noaa |> 
  mutate(year = year(date),
         month = month(date),
         day = day(date))
```

- Ensure observations for temperature, precipitation, and snowfall are
  given in reasonable units we want the units for “snow” and “snwd” to
  be tenths of mm and transfer the “tmax” and “tmin” to muneric
  characters.

``` r
ny_noaa = ny_noaa |>
  mutate(tmax = as.numeric(tmax)) |>
  mutate(tmin = as.numeric(tmin)) |>
  mutate(
    snow = ifelse(is.na(snow), NA, snow * 1/10),
    snwd = ifelse(is.na(snwd), NA, snwd * 1/10)
  )
```

- most commonly observed values for snowfall

``` r
common_snowfall = ny_noaa |> 
  count(snow) |> 
  arrange(desc(n))

print(common_snowfall)
```

    ## # A tibble: 282 × 2
    ##     snow       n
    ##    <dbl>   <int>
    ##  1   0   2008508
    ##  2  NA    381221
    ##  3   2.5   31022
    ##  4   1.3   23095
    ##  5   5.1   18274
    ##  6   7.6   10173
    ##  7   0.8    9962
    ##  8   0.5    9748
    ##  9   3.8    9197
    ## 10   0.3    8790
    ## # ℹ 272 more rows

We could find out that the most commonly observed value for snowfall is
0.0, which is 381221 times. I think this is because that snowfall is not
a daily occurrence in most regions. Many places experience long periods
without any snowfall, especially during non-winter months. Even in
regions where snow is common, there are often days when no snow falls.
The second most commonly observed value is `NA`, indicating missingness.

Question2: - Make a two-panel plot showing the average max temperature
in January and in July in each station across years.

``` r
ny_noaa_filtered_plot = ny_noaa |> 
  filter(month %in% c(1, 7)) |> 
  group_by(id, year, month) |> 
  summarize(avg_tmax = mean(tmax, na.rm = TRUE)) |> 
  ggplot(aes(x = year, y = avg_tmax)) +
  geom_point() +
  facet_grid(. ~ month) +
  labs(
    title = "Average Maximum Temperature in January and July",
    x = "Year",
    y = "Average Max Temperature (°C)"
  ) 
```

    ## `summarise()` has grouped output by 'id', 'year'. You can override using the
    ## `.groups` argument.

``` r
print(ny_noaa_filtered_plot)
```

    ## Warning: Removed 5970 rows containing missing values or values outside the scale range
    ## (`geom_point()`).

<img src="p8105_hw3_yc4584_files/figure-gfm/two-panel plot showing the average max temperature-1.png" width="90%" />

- A short discription:Is there any observable / interpretable structure?
  Any outliers? From the plot, we could see that the average maximum
  temperature in January is lower than that in July. The average maximum
  temperature in July is more stable than that In January. There are
  some outliers in the plot, but they are not very significant. The
  outliers in the January plot are approximately equally distributed in
  the lower and higher parts of the plot. The outliers in the July plot
  are mainly distributed in the lower part of the plot.

Question3: - Part (i): tmax vs tmin plot using hexbin plot

``` r
p1 = ggplot(ny_noaa, aes(x = tmin, y = tmax)) +
  geom_hex() +
  labs(
    title = "tmax vs tmin",
    x = "Minimum Temperature (°C)",
    y = "Maximum Temperature (°C)",
    fill = "Count"
  ) 
print(p1)
```

    ## Warning: Removed 1136276 rows containing non-finite outside the scale range
    ## (`stat_binhex()`).

<img src="p8105_hw3_yc4584_files/figure-gfm/tmax vs tmin plot-1.png" width="90%" />
Part (ii): Distribution of snowfall values \> 0 and \< 100, separated by
year

``` r
p2 = ny_noaa |> 
  filter(snow > 0 & snow < 100) |> 
  ggplot(aes(x = snow, y = as.factor(year))) + 
  geom_density_ridges() +
  labs(
    title = "Distribution of Snowfall (0 < snowfall < 100)",
    x = "Snowfall (tenths of mm)",
    y = "Year"
  )
print(p2)
```

    ## Picking joint bandwidth of 0.622

<img src="p8105_hw3_yc4584_files/figure-gfm/Distribution of snowfall values-1.png" width="90%" />

Combination of p1 and p2

``` r
library(gridExtra)
```

    ## 
    ## 载入程序包：'gridExtra'

    ## The following object is masked from 'package:dplyr':
    ## 
    ##     combine

``` r
grid.arrange(p1, p2, nrow = 1) 
```

    ## Warning: Removed 1136276 rows containing non-finite outside the scale range
    ## (`stat_binhex()`).

    ## Picking joint bandwidth of 0.622

<img src="p8105_hw3_yc4584_files/figure-gfm/Combination of p1 and p2-1.png" width="90%" />

# Problem 2

Load data

``` r
demographic_df = read_csv("./data/nhanes_covar.csv", skip = 4)
```

    ## Rows: 250 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (5): SEQN, sex, age, BMI, education
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
accelerometer_df = read_csv("./data/nhanes_accel.csv")
```

    ## Rows: 250 Columns: 1441
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (1441): SEQN, min1, min2, min3, min4, min5, min6, min7, min8, min9, min1...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

tidy the data

``` r
demographic_df = demographic_df |> 
  janitor::clean_names() |>
  drop_na() |> 
  filter(age >= 21) |> 
  mutate(sex = as.character(sex)) |> 
  mutate(
    sex = case_when(
      sex == "1" ~ "male",
      sex == "2" ~ "female")) |>
  mutate(education = as.character(education)) |> 
  mutate(
    education = case_when(
      education == "1" ~ "less than high school",
      education == "2" ~ "high school equivalent",
      education == "3" ~ "more than high school")) |> 
  mutate(
    education = factor(
      education, 
      levels = c("less than high school", "high school equivalent", "more than high school")))
```

``` r
accelerometer_df = accelerometer_df |> 
  janitor::clean_names()
```

merge the data sets

``` r
merge_df = left_join(demographic_df, accelerometer_df, by = "seqn")
print(merge_df)
```

    ## # A tibble: 228 × 1,445
    ##     seqn sex      age   bmi education     min1   min2   min3  min4   min5   min6
    ##    <dbl> <chr>  <dbl> <dbl> <fct>        <dbl>  <dbl>  <dbl> <dbl>  <dbl>  <dbl>
    ##  1 62161 male      22  23.3 high school… 1.11  3.12   1.47   0.938 1.60   0.145 
    ##  2 62164 female    44  23.2 more than h… 1.92  1.67   2.38   0.935 2.59   5.22  
    ##  3 62169 male      21  20.1 high school… 5.85  5.18   4.76   6.48  6.85   7.24  
    ##  4 62174 male      80  33.9 more than h… 5.42  3.48   3.72   3.81  6.85   4.45  
    ##  5 62177 male      51  20.1 high school… 6.14  8.06   9.99   6.60  4.57   2.78  
    ##  6 62178 male      80  28.5 high school… 0.167 0.429  0.131  1.20  0.0796 0.0487
    ##  7 62180 male      35  27.9 more than h… 0.039 0      0      0     0.369  0.265 
    ##  8 62184 male      26  22.1 high school… 1.55  2.81   3.86   4.76  6.10   7.61  
    ##  9 62189 female    30  22.4 more than h… 2.81  0.195  0.163  0     0.144  0.180 
    ## 10 62199 male      57  28   more than h… 0.031 0.0359 0.0387 0.079 0.109  0.262 
    ## # ℹ 218 more rows
    ## # ℹ 1,434 more variables: min7 <dbl>, min8 <dbl>, min9 <dbl>, min10 <dbl>,
    ## #   min11 <dbl>, min12 <dbl>, min13 <dbl>, min14 <dbl>, min15 <dbl>,
    ## #   min16 <dbl>, min17 <dbl>, min18 <dbl>, min19 <dbl>, min20 <dbl>,
    ## #   min21 <dbl>, min22 <dbl>, min23 <dbl>, min24 <dbl>, min25 <dbl>,
    ## #   min26 <dbl>, min27 <dbl>, min28 <dbl>, min29 <dbl>, min30 <dbl>,
    ## #   min31 <dbl>, min32 <dbl>, min33 <dbl>, min34 <dbl>, min35 <dbl>, …

men and women in each education category

``` r
gender_education_df = merge_df |> 
  group_by(sex, education) |>
  summarize(count = n()) |> 
  pivot_wider(names_from = education, values_from = count)
```

    ## `summarise()` has grouped output by 'sex'. You can override using the `.groups`
    ## argument.

``` r
print(gender_education_df)
```

    ## # A tibble: 2 × 4
    ## # Groups:   sex [2]
    ##   sex    `less than high school` `high school equivalent` more than high schoo…¹
    ##   <chr>                    <int>                    <int>                  <int>
    ## 1 female                      28                       23                     59
    ## 2 male                        27                       35                     56
    ## # ℹ abbreviated name: ¹​`more than high school`

age distribution for men and women in different education

``` r
hist_distribution = merge_df |>
  ggplot(aes(x = age, fill = sex)) +
  geom_histogram(alpha = 0.5, position = "identity") +
  facet_wrap(~ education) +
  labs(
    title = "Age Distribution by Gender in Each Education Category",
    x = "Age",
    y = "Count",
    fill = "Gender"
  ) 
print(hist_distribution)
```

    ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.

<img src="p8105_hw3_yc4584_files/figure-gfm/age distribution-1.png" width="90%" />
We could see from this histogram and the table that in this study the
people from the “more than high school” education category are the most,
and the number of people from the “less than high school” and “high
school equivalent” education category are similar. In the “high school
equivalent” education level, the number of women are more than men, but
in the other two education levels, the number of men and women are
similar. The age distribution in the “more than high school” education
category is more concentrated in the younger age, and the age
distribution in the “less than high school” education category is more
concentrated in the older age. The age distribution in the “high school
equivalent” education category is concentrated in the extreme young and
extreme old age, the distribution in the middle age is pretty much even.

plot total activity against age

``` r
start_col = which(names(merge_df) == "min1")
end_col = which(names(merge_df) == "min1440")
numeric_cols_to_sum = names(merge_df)[start_col:end_col]
merge_df$total_activity = rowSums(merge_df[numeric_cols_to_sum])
print(merge_df)
```

    ## # A tibble: 228 × 1,446
    ##     seqn sex      age   bmi education     min1   min2   min3  min4   min5   min6
    ##    <dbl> <chr>  <dbl> <dbl> <fct>        <dbl>  <dbl>  <dbl> <dbl>  <dbl>  <dbl>
    ##  1 62161 male      22  23.3 high school… 1.11  3.12   1.47   0.938 1.60   0.145 
    ##  2 62164 female    44  23.2 more than h… 1.92  1.67   2.38   0.935 2.59   5.22  
    ##  3 62169 male      21  20.1 high school… 5.85  5.18   4.76   6.48  6.85   7.24  
    ##  4 62174 male      80  33.9 more than h… 5.42  3.48   3.72   3.81  6.85   4.45  
    ##  5 62177 male      51  20.1 high school… 6.14  8.06   9.99   6.60  4.57   2.78  
    ##  6 62178 male      80  28.5 high school… 0.167 0.429  0.131  1.20  0.0796 0.0487
    ##  7 62180 male      35  27.9 more than h… 0.039 0      0      0     0.369  0.265 
    ##  8 62184 male      26  22.1 high school… 1.55  2.81   3.86   4.76  6.10   7.61  
    ##  9 62189 female    30  22.4 more than h… 2.81  0.195  0.163  0     0.144  0.180 
    ## 10 62199 male      57  28   more than h… 0.031 0.0359 0.0387 0.079 0.109  0.262 
    ## # ℹ 218 more rows
    ## # ℹ 1,435 more variables: min7 <dbl>, min8 <dbl>, min9 <dbl>, min10 <dbl>,
    ## #   min11 <dbl>, min12 <dbl>, min13 <dbl>, min14 <dbl>, min15 <dbl>,
    ## #   min16 <dbl>, min17 <dbl>, min18 <dbl>, min19 <dbl>, min20 <dbl>,
    ## #   min21 <dbl>, min22 <dbl>, min23 <dbl>, min24 <dbl>, min25 <dbl>,
    ## #   min26 <dbl>, min27 <dbl>, min28 <dbl>, min29 <dbl>, min30 <dbl>,
    ## #   min31 <dbl>, min32 <dbl>, min33 <dbl>, min34 <dbl>, min35 <dbl>, …

``` r
scatterplot_total_activity = merge_df |>
  ggplot(aes(x = age, y = total_activity, color = sex)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "loess", se = FALSE) + 
  facet_wrap(~ education) +  
  labs(title = "Total Activities by Age, Gender, and Education Level",
       x = "Age",
       y = "Total Activity",
       color = "Gender") 
print(scatterplot_total_activity)
```

    ## `geom_smooth()` using formula = 'y ~ x'

<img src="p8105_hw3_yc4584_files/figure-gfm/plot scatterplot-1.png" width="90%" />
comment: From the plot, we could see that the general trends of total
activity in all types of population are decreasing with age. However,
with age growing, the total activity of people with “less than high
school” education level is decreasing faster than the other two
education levels. The total activity of people with “more than high
school” education level is decreasing slower than the other two
education levels. Specifically, there is a peak of total activity in the
population with “less than high school” education level at the age of
around 60. For the people with “high school equivalent” education level,
the increase or peak is at the age of around 40. For the people with
“more than high school” education level, the trend is more stable and
the peak for women is at the age of around 50, for man is at the age of
around 60. For sex, in both “high school equivalent” and “more than high
school”, the total activity in women is lower than men at the same age.
However, in the “less than high school” education level, the women older
than 40 have higher total activity than men at the same age.

24 hours activity time course

``` r
time_course = merge_df |>
  select(seqn, sex, education, starts_with("min")) |>
  pivot_longer(cols = starts_with("min"), names_to = "minute", values_to = "activity") |>
  mutate(minute = as.numeric(str_remove(minute, "min"))) 
```

``` r
time_course_plot = 
  ggplot(time_course, aes(x = minute, y = activity, color = sex)) +
  geom_line(alpha = 0.6) +
  geom_smooth(method = "loess", se = FALSE, linetype = "dashed") +
  facet_wrap(~ education) +
  labs(title = "24-Hour Activity Time Courses by Education Level",
       x = "Minute of the Day",
       y = "Activity Time",
       color = "Gender")
print(time_course_plot)
```

    ## `geom_smooth()` using formula = 'y ~ x'

<img src="p8105_hw3_yc4584_files/figure-gfm/plot 24 hours activity time course-1.png" width="90%" />

comment: We could see from the plot that the highest activity time in a
day for different educational level is different, but the lowest
activity time for them all are around 4:00-5:00. For the people with
“less than high school” education level, the highest activity time is
around 10:00-11:00, and the activity time is decreasing after that. For
the people with “high school equivalent” education level, the highest
activity time is around 8:00-9:00, and the activity time is decreasing
after that with a small peak at around 19:00-20:00 for women in this
educational type. For the people with “more than high school” education
level, the highest activity time is around 8:00-9:00 for men and
20:00-21:00 for women, and the activity time is relatively low between
these. In general, the activity time of people with “more than high
school” education level is higher than the other two education levels.
Although there are difference in the activity time between gender and
educational level, the general trend in three panels are similar. The
activity time is increasing to peak of the day at 12:00-13:00 and
decreasing. Also, the difference between gender is not very significant.
Maybe, the women with “less than high school” education level has
slightly more activity time than men in this educational level, but the
difference is not very significant. In the other two panels, activity
time for men is slightly higher than women.

# Problem 3

Import, clean, and tidy these data, and describe the resulting dataset.

``` r
citi_jan_2020_df = read_csv("./data/citibike/Jan 2020 Citi.csv")
```

    ## Rows: 12420 Columns: 7
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (6): ride_id, rideable_type, weekdays, start_station_name, end_station_n...
    ## dbl (1): duration
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
citi_jan_2024_df = read_csv("./data/citibike/Jan 2024 Citi.csv")
```

    ## Rows: 18861 Columns: 7
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (6): ride_id, rideable_type, weekdays, start_station_name, end_station_n...
    ## dbl (1): duration
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
citi_july_2020_df = read_csv("./data/citibike/July 2020 Citi.csv")
```

    ## Rows: 21048 Columns: 7
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (6): ride_id, rideable_type, weekdays, start_station_name, end_station_n...
    ## dbl (1): duration
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
citi_july_2024_df = read_csv("./data/citibike/July 2024 Citi.csv")
```

    ## Rows: 47156 Columns: 7
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (6): ride_id, rideable_type, weekdays, start_station_name, end_station_n...
    ## dbl (1): duration
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

check the data frame

``` r
head(citi_jan_2020_df)
```

    ## # A tibble: 6 × 7
    ##   ride_id    rideable_type weekdays duration start_station_name end_station_name
    ##   <chr>      <chr>         <chr>       <dbl> <chr>              <chr>           
    ## 1 4BE06CB33… classic_bike  Tuesday     15.3  Columbus Ave & W … E 53 St & Madis…
    ## 2 26886E034… classic_bike  Wednesd…     5.31 2 Ave & E 96 St    1 Ave & E 110 St
    ## 3 24DC56060… classic_bike  Friday       9.69 Columbia St & Riv… Grand St & Eliz…
    ## 4 EEDC10535… classic_bike  Sunday       7.00 W 84 St & Columbu… Columbus Ave & …
    ## 5 2CD4BD4CE… classic_bike  Friday       2.85 Forsyth St & Broo… Suffolk St & St…
    ## 6 E18682F9A… classic_bike  Sunday      25.5  Allen St & Hester… Atlantic Ave & …
    ## # ℹ 1 more variable: member_casual <chr>

``` r
head(citi_jan_2024_df)
```

    ## # A tibble: 6 × 7
    ##   ride_id    rideable_type weekdays duration start_station_name end_station_name
    ##   <chr>      <chr>         <chr>       <dbl> <chr>              <chr>           
    ## 1 644A0105A… electric_bike Wednesd…    16.5  Lafayette St & Je… W 50 St & 9 Ave 
    ## 2 A5A8C0AD1… electric_bike Wednesd…     6.29 Clinton St & Till… Duffield St & W…
    ## 3 B392CE349… electric_bike Tuesday      6.12 West End Ave & W … W 116 St & Broa…
    ## 4 33756EDC7… electric_bike Wednesd…    10.9  Grand St & Elizab… Front St & Jay …
    ## 5 29D9AF64D… electric_bike Thursday     8.42 12 Ave & W 40 St   Washington St &…
    ## 6 C7E61191A… electric_bike Sunday      18.5  7 Ave & Central P… 44 Dr & Jackson…
    ## # ℹ 1 more variable: member_casual <chr>

``` r
head(citi_july_2020_df)
```

    ## # A tibble: 6 × 7
    ##   ride_id    rideable_type weekdays duration start_station_name end_station_name
    ##   <chr>      <chr>         <chr>       <dbl> <chr>              <chr>           
    ## 1 A7503F194… classic_bike  Sunday       9.86 Franklin Ave & Em… Grand Army Plaz…
    ## 2 B47EBE0EA… classic_bike  Monday       8.29 E 33 St & 1 Ave    E 33 St & 5 Ave 
    ## 3 8146F6C68… classic_bike  Wednesd…     5.39 George St & Wilso… Willoughby Ave …
    ## 4 D49560E33… classic_bike  Saturday    19.2  St. Nicholas Ave … Willis Ave & E …
    ## 5 87687AAE4… classic_bike  Tuesday     26.4  Front St & Jay St  Grand St & Eliz…
    ## 6 E30DFCD98… classic_bike  Sunday      51.9  Clinton St & Jora… Myrtle Ave & Li…
    ## # ℹ 1 more variable: member_casual <chr>

``` r
head(citi_july_2024_df)
```

    ## # A tibble: 6 × 7
    ##   ride_id    rideable_type weekdays duration start_station_name end_station_name
    ##   <chr>      <chr>         <chr>       <dbl> <chr>              <chr>           
    ## 1 86AE148E3… classic_bike  Sunday      19.7  Picnic Point       Yankee Ferry Te…
    ## 2 FCF07A30F… electric_bike Thursday     7.68 W 54 St & 9 Ave    W 42 St & 8 Ave 
    ## 3 D8397E843… classic_bike  Thursday    24.5  12 Ave & W 40 St   W 84 St & Amste…
    ## 4 E575690C1… electric_bike Tuesday      3.53 Grand St & Haveme… S 4 St & Rodney…
    ## 5 184AABED4… electric_bike Wednesd…    24.1  Broadway & Kent A… Henry St & Degr…
    ## 6 ACA61A92B… classic_bike  Saturday     7.83 E 1 St & 1 Ave     Mercer St & Spr…
    ## # ℹ 1 more variable: member_casual <chr>

check for missing data

``` r
na_counts_jan_2020 = colSums(is.na(citi_jan_2020_df))
na_counts_jan_2024 = colSums(is.na(citi_jan_2024_df))
na_counts_july_2020 = colSums(is.na(citi_july_2020_df))
na_counts_july_2024 = colSums(is.na(citi_july_2024_df))
```

We could find that most missing values are concentrated in the column of
“start_station_name” and “end_station_name” in each of the four charts.
Because the number of missing data is not very large, we could drop the
missing data in these columns.

clean and tidy the data

``` r
citi_jan_2020_df = citi_jan_2020_df |> 
  janitor::clean_names() |>
  drop_na(start_station_name, end_station_name) |>
  mutate(year = 2020, month = 1) |> 
  mutate(weekdays = case_when(
    weekdays == "Monday" ~ 1,
    weekdays == "Tuesday" ~ 2,
    weekdays == "Wednesday" ~ 3,
    weekdays == "Thursday" ~ 4,
    weekdays == "Friday" ~ 5,
    weekdays == "Saturday" ~ 6,
    weekdays == "Sunday" ~ 7)) |> 
  filter(duration <= 240) |> 
  select(ride_id, member_casual, year, month, everything())
print(citi_jan_2020_df)
```

    ## # A tibble: 12,398 × 9
    ##    ride_id          member_casual  year month rideable_type weekdays duration
    ##    <chr>            <chr>         <dbl> <dbl> <chr>            <dbl>    <dbl>
    ##  1 4BE06CB33B037044 member         2020     1 classic_bike         2    15.3 
    ##  2 26886E034974493B member         2020     1 classic_bike         3     5.31
    ##  3 24DC56060EBE6260 member         2020     1 classic_bike         5     9.69
    ##  4 EEDC1053582D02E5 member         2020     1 classic_bike         7     7.00
    ##  5 2CD4BD4CEE2E50A9 member         2020     1 classic_bike         5     2.85
    ##  6 E18682F9A4E501BB member         2020     1 classic_bike         7    25.5 
    ##  7 B9B2E8960A71A284 member         2020     1 classic_bike         7     3.65
    ##  8 DEF8F50495E64691 member         2020     1 classic_bike         7    38.3 
    ##  9 17D44DA993F32573 member         2020     1 classic_bike         4    38.5 
    ## 10 0FD113A309327E8C member         2020     1 classic_bike         2     6.52
    ## # ℹ 12,388 more rows
    ## # ℹ 2 more variables: start_station_name <chr>, end_station_name <chr>

``` r
citi_jan_2024_df = citi_jan_2024_df |> 
  janitor::clean_names() |>
  drop_na(start_station_name, end_station_name) |>
  mutate(year = 2024, month = 1) |> 
  mutate(weekdays = case_when(
    weekdays == "Monday" ~ 1,
    weekdays == "Tuesday" ~ 2,
    weekdays == "Wednesday" ~ 3,
    weekdays == "Thursday" ~ 4,
    weekdays == "Friday" ~ 5,
    weekdays == "Saturday" ~ 6,
    weekdays == "Sunday" ~ 7)) |> 
  filter(duration <= 240) |> 
  select(ride_id, member_casual, year, month, everything())
print(citi_jan_2024_df)
```

    ## # A tibble: 18,799 × 9
    ##    ride_id          member_casual  year month rideable_type weekdays duration
    ##    <chr>            <chr>         <dbl> <dbl> <chr>            <dbl>    <dbl>
    ##  1 644A0105ACA27B15 member         2024     1 electric_bike        3    16.5 
    ##  2 A5A8C0AD18EDA2C0 member         2024     1 electric_bike        3     6.29
    ##  3 B392CE3496831A89 member         2024     1 electric_bike        2     6.12
    ##  4 33756EDC77800B6A member         2024     1 electric_bike        3    10.9 
    ##  5 29D9AF64D6593D9B member         2024     1 electric_bike        4     8.42
    ##  6 C7E61191A30649D5 member         2024     1 electric_bike        7    18.5 
    ##  7 947A4F86ED40F657 member         2024     1 electric_bike        7     3.45
    ##  8 0AD92E71246A2548 casual         2024     1 electric_bike        1    14.9 
    ##  9 CE2C128DB7D3B534 member         2024     1 electric_bike        5     9.55
    ## 10 DAAB66B114F1689C member         2024     1 electric_bike        7     4.87
    ## # ℹ 18,789 more rows
    ## # ℹ 2 more variables: start_station_name <chr>, end_station_name <chr>

``` r
citi_july_2020_df = citi_july_2020_df |> 
  janitor::clean_names() |>
  drop_na(start_station_name, end_station_name) |>
  mutate(year = 2020, month = 7) |> 
  mutate(weekdays = case_when(
    weekdays == "Monday" ~ 1,
    weekdays == "Tuesday" ~ 2,
    weekdays == "Wednesday" ~ 3,
    weekdays == "Thursday" ~ 4,
    weekdays == "Friday" ~ 5,
    weekdays == "Saturday" ~ 6,
    weekdays == "Sunday" ~ 7)) |> 
  filter(duration <= 240) |> 
  select(ride_id, member_casual, year, month, everything())
print(citi_july_2020_df)
```

    ## # A tibble: 21,013 × 9
    ##    ride_id          member_casual  year month rideable_type weekdays duration
    ##    <chr>            <chr>         <dbl> <dbl> <chr>            <dbl>    <dbl>
    ##  1 A7503F194A7CB244 member         2020     7 classic_bike         7     9.86
    ##  2 B47EBE0EA71E3275 member         2020     7 classic_bike         1     8.29
    ##  3 8146F6C6855338C8 member         2020     7 classic_bike         3     5.39
    ##  4 D49560E3308D2128 member         2020     7 classic_bike         6    19.2 
    ##  5 87687AAE400824DE member         2020     7 classic_bike         2    26.4 
    ##  6 E30DFCD98462C9F9 casual         2020     7 classic_bike         7    51.9 
    ##  7 0C53CC4645259D32 casual         2020     7 classic_bike         2    15.7 
    ##  8 34B0268510C0DAF0 member         2020     7 classic_bike         3     8.39
    ##  9 1537706795882483 member         2020     7 classic_bike         2     5.56
    ## 10 A834D6A09893E5E6 member         2020     7 classic_bike         3    14.3 
    ## # ℹ 21,003 more rows
    ## # ℹ 2 more variables: start_station_name <chr>, end_station_name <chr>

``` r
citi_july_2024_df = citi_july_2024_df |> 
  janitor::clean_names() |>
  drop_na(start_station_name, end_station_name) |>
  mutate(year = 2024, month = 7) |> 
  mutate(weekdays = case_when(
    weekdays == "Monday" ~ 1,
    weekdays == "Tuesday" ~ 2,
    weekdays == "Wednesday" ~ 3,
    weekdays == "Thursday" ~ 4,
    weekdays == "Friday" ~ 5,
    weekdays == "Saturday" ~ 6,
    weekdays == "Sunday" ~ 7)) |> 
  filter(duration <= 240) |> 
  select(ride_id, member_casual, year, month, everything())
print(citi_july_2024_df)
```

    ## # A tibble: 47,043 × 9
    ##    ride_id          member_casual  year month rideable_type weekdays duration
    ##    <chr>            <chr>         <dbl> <dbl> <chr>            <dbl>    <dbl>
    ##  1 86AE148E36FBF035 casual         2024     7 classic_bike         7    19.7 
    ##  2 FCF07A30F66B9B07 casual         2024     7 electric_bike        4     7.68
    ##  3 D8397E843C06644D member         2024     7 classic_bike         4    24.5 
    ##  4 E575690C13424E8C member         2024     7 electric_bike        2     3.53
    ##  5 184AABED46DCE11A casual         2024     7 electric_bike        3    24.1 
    ##  6 ACA61A92B5EA0D11 member         2024     7 classic_bike         6     7.83
    ##  7 C48F946C8105F570 member         2024     7 classic_bike         7     4.85
    ##  8 F3072F6E661ADC41 member         2024     7 classic_bike         6     4.33
    ##  9 8A28359430921ACC member         2024     7 electric_bike        4    12.6 
    ## 10 EFFCEE4CF0ADEF05 casual         2024     7 electric_bike        5    10.6 
    ## # ℹ 47,033 more rows
    ## # ℹ 2 more variables: start_station_name <chr>, end_station_name <chr>

summarize the data

The data frame contains the information of the citibike rides in January
and July of 2020 and 2024. The key variables are “ride_id”,
“member_casual”, “year”, “month”, “rideable_type”, “weekdays”,
“start_station_name”, “end_station_name”, “duration”. The “ride_id” is a
unique identifier for each ride, the “member_casual” is a character
variable indicating whether the rider is a member or a casual rider. The
“year”, “month” and “weekdays” are the year, month and weekday of the
ride. The “rideable_type” tells whether the bike people rent is a
classic bike or a electric bike. The “start_station_name” and
“end_station_name” are the start and end station of the ride. The
“duration” is the duration of the ride in minutes. All the columns
except “year”, “month”, “weekdays” and “duration” are character
variables. The min, 1st quantile, median, 3rd quantile, max and mean
duration in “citi_jan_2020_df” are 1.008, 5.284, 8.866, 15.137, 231.161
and 11.921. For citi_jan_2024_df, they are 1.002, 4.623, 7.664, 12.964,
225.526, 10.499 For citi_july_2020_df, they are 1.006, 7.966, 14.552,
24.817, 238.780, 18.926 For citi_july_2024_df, they are 1.008, 5.482,
9.593, 16.729, 232.051, 13.402 We could find that in the same year, the
average ride time in January is always shorter than that in July. In the
same month of different year, the average ride time in 2024 is shorter
than that in 2020. Also, the number of people who use citybike in July
is more than that in January in the same year. In the same month, the
number of people who use citybike in 2024 is more than that in 2020.

Produce a reader-friendly table showing the total number of rides in
each combination of year and month separating casual riders and Citi
Bike members.

First, we need to combine the four data frames into one data frame.

``` r
citi_df = bind_rows(citi_jan_2020_df, citi_jan_2024_df, citi_july_2020_df, citi_july_2024_df)
```

Then, we could produce the table.

``` r
citi_df |>
  group_by(year, month, member_casual) |>
  summarize(count = n()) |>
  pivot_wider(names_from = member_casual, values_from = count)
```

    ## `summarise()` has grouped output by 'year', 'month'. You can override using the
    ## `.groups` argument.

    ## # A tibble: 4 × 4
    ## # Groups:   year, month [4]
    ##    year month casual member
    ##   <dbl> <dbl>  <int>  <int>
    ## 1  2020     1    980  11418
    ## 2  2020     7   5625  15388
    ## 3  2024     1   2094  16705
    ## 4  2024     7  10843  36200

From the table, we could see that the number of casual and member riders
are always bigger in July than in January in the same year, which may be
because of the weather. In the same month, the number of member riders
is always bigger than the number of casual riders, which may be because
of the lower rental rate for member riders. Also, we could see that the
user of citibike is increasing from 2020 to 2024, which shows that the
citibike is becoming more and more popular.

Make a table showing the 5 most popular starting stations for July 2024;
include the number of rides originating from these stations.

``` r
citi_july_2024_df |>
  group_by(start_station_name) |>
  summarize(count = n()) |>
  arrange(desc(count)) |>
  head(5)
```

    ## # A tibble: 5 × 2
    ##   start_station_name       count
    ##   <chr>                    <int>
    ## 1 Pier 61 at Chelsea Piers   163
    ## 2 University Pl & E 14 St    155
    ## 3 W 21 St & 6 Ave            152
    ## 4 West St & Chambers St      150
    ## 5 W 31 St & 7 Ave            145

So we could know that the 5 most popular starting stations for July 2024
are above

Make a plot to investigate the effects of day of the week, month, and
year on median ride duration. This plot can include one or more panels,
but should facilitate comparison across all variables of interest.

``` r
p <- citi_df |>
  group_by(year, month, weekdays) |>
  summarize(median_duration = median(duration)) |>
  ggplot(aes(x = weekdays, y = median_duration, color = factor(year))) +
  scale_x_continuous(breaks = 1:7) +
  geom_point() +
  geom_line() +
  facet_wrap(~ month) +
  labs(
    title = "Median Ride Duration by Day of the Week, Month, and Year",
    x = "Weekdays (1 = Monday, 7 = Sunday)",
    y = "Median Ride Duration (minutes)",
    color = "Year"
  )
```

    ## `summarise()` has grouped output by 'year', 'month'. You can override using the
    ## `.groups` argument.

``` r
print(p)
```

<img src="p8105_hw3_yc4584_files/figure-gfm/calculate the median ride duration-1.png" width="90%" />

From the plot, we could see that the median ride duration is generally
longer in 2020 than in 2024 in the same month and the same weekday,
which might be because the citibike is less popular in 2020 or because
with time going, the perspective of riding a bike is weakened. Also, the
median ride duration is longer in July than in January in the same
weekday and the same year, which could be because the weather in July is
more suitable for biking. Besides, I found that for the trend of median
ride duration in a week, there is always a peak at the weekend, on which
people have more free time and always a valley on Friday, on which
people tend to have a rest after a week’s work. The peak and valley are
more significant in 2020 than in 2024.

There were relatively few electric Citi Bikes in 2020, but many more are
available now. For data in 2024, make a figure that shows the impact of
month, membership status, and bike type on the distribution of ride
duration.

``` r
citi_df_2024 = bind_rows(citi_jan_2024_df, citi_july_2024_df)
p1 <- citi_df_2024 |> 
  ggplot(aes(x = duration, fill = member_casual)) +
  geom_histogram(binwidth = 5, position = "dodge", alpha = 0.7) +
  facet_wrap(~ month + rideable_type) +
  labs(
    title = "Impact of Month, Membership Status, and Bike Type on Ride Duration (2024)",
    x = "Ride Duration (minutes)",
    y = "Count",
    fill = "Membership Status"
  )
print(p1)
```

<img src="p8105_hw3_yc4584_files/figure-gfm/calculate the distribution of ride duration-1.png" width="90%" />

``` r
p2 <- citi_df_2024 |>
  ggplot(aes(x = factor(month), y = duration, fill = member_casual)) +
  geom_boxplot() +
  facet_wrap(~ rideable_type) +
  labs(
    title = "Impact of Month, Membership Status, and Bike Type on Ride Duration (2024)",
    x = "Month",
    y = "Ride Duration (minutes)",
    fill = "Membership Status"
  )
print(p2)
```

<img src="p8105_hw3_yc4584_files/figure-gfm/calculate the distribution of ride duration-2.png" width="90%" />

We could find from the box plot that the duration time for January and
July in 2024 mainly are concentrated in the range of 0-50 minutes but
still contain many outliers ranging from 100 to 200, which could explain
the extreme right skewed in the histogram. The median duration time for
electric bikes is generally shorter than that for classic bikes. The
distribution of ride duration for electric bikes is more concentrated
than that for classic bikes. For histogram, we could see that the
frequency of riding electric bikes significantly higher than riding
classic bikes in 2024 no matter in January or July and no matter the
rider is a member or a casual rider. For membership status, there are
more member riders than casual riders in 2024. They both are mainly
concentrated between the duration of 0-50 minutes. The distribution of
ride duration for member riders is more concentrated than that for
casual riders. Also, the distribution of ride duration for member riders
is more right skewed than that for casual riders. For month, the
distribution of ride duration in July is more right skewed than that in
January. The frequency of ride duration in July is more than that in
January in general.
