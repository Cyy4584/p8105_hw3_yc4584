---
title: "p8105_hw3_yc4584"
author: "Yingyu Cui"
date: "2024-10-08"
output: github_document
---

```{r setup and figure preferrences}
library(tidyverse)
library(ggridges)
library(patchwork)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Problem 1
```{r load data}
library(p8105.datasets)
data("ny_noaa")
```


```{r NA data check}
na_counts = colSums(is.na(ny_noaa))

print(na_counts)
```

- A short discription:
 This dataset contains `r nrow(ny_noaa)` rows and `r ncol(ny_noaa)` columns. The data frame contains the information of the weather in New York from January 1, 1981 through December 31, 2010. The key variables are "date", "temperature_min", "temperature_max", "precipitation", "snowfall", "snow_depth". In all of the variables, the "prcp", "snow" and "snwd" variables are numeric variables and the "tmax", "tmin" and "id" are recognized as character variables. However, I would prefer to transfer "tman" and "tmin" into numeric characters. The missing data in every column is shown in the following table. 
     id    date    prcp    snow    snwd    tmax    tmin 
      0       0  145838  381221  591786 1134358 1134420 
We can see that there are around half of the data missing in the "tmax" and "tmin" columns. In "prcp", "snow" and "snwd" columns, there are less data missing, but still a large amount of data missing.

Question 1:
- Create separate variables for year, month, and day
```{r create variables}
ny_noaa = ny_noaa |> 
  mutate(year = year(date),
         month = month(date),
         day = day(date))
```

- Ensure observations for temperature, precipitation, and snowfall are given in reasonable units
we want the units for "snow" and "snwd" to be tenths of mm and transfer the "tmax" and "tmin" to muneric characters. 
```{r change units}
ny_noaa = ny_noaa |>
  mutate(tmax = as.numeric(tmax)) |>
  mutate(tmin = as.numeric(tmin)) |>
  mutate(
    snow = ifelse(is.na(snow), NA, snow * 1/10),
    snwd = ifelse(is.na(snwd), NA, snwd * 1/10)
  )
```

-  most commonly observed values for snowfall
```{r most commonly observed values for snowfall}
common_snowfall = ny_noaa |> 
  count(snow) |> 
  arrange(desc(n))

print(common_snowfall)
```
We could find out that the most commonly observed value for snowfall is 0.0, which is 381221 times. I think this is because that snowfall is not a daily occurrence in most regions. Many places experience long periods without any snowfall, especially during non-winter months. Even in regions where snow is common, there are often days when no snow falls. The second most commonly observed value is `NA`, indicating missingness.


Question2:
- Make a two-panel plot showing the average max temperature in January and in July in each station across years.
```{r two-panel plot showing the average max temperature}
ny_noaa_filtered_plot = ny_noaa |> 
  filter(month %in% c(1, 7)) |> 
  group_by(id, year, month) |> 
  summarize(avg_tmax = mean(tmax, na.rm = TRUE)) |> 
  ggplot(aes(x = year, y = avg_tmax)) +
  geom_point() +
  facet_grid(. ~ month) +
  labs(
    title = "Average Maximum Temperature in January and July",
    x = "Year",
    y = "Average Max Temperature (°C)"
  ) 
print(ny_noaa_filtered_plot)
```

- A short discription:Is there any observable / interpretable structure? Any outliers?
From the plot, we could see that the average maximum temperature in January is lower than that in July. The average maximum temperature in July is more stable than that In January. There are some outliers in the plot, but they are not very significant. The outliers in the January plot are approximately equally distributed in the lower and higher parts of the plot. The outliers in the July plot are mainly distributed in the lower part of the plot.


Question3:
- Part (i): tmax vs tmin plot using hexbin plot
```{r tmax vs tmin plot}
p1 = ggplot(ny_noaa, aes(x = tmin, y = tmax)) +
  geom_hex() +
  labs(
    title = "tmax vs tmin",
    x = "Minimum Temperature (°C)",
    y = "Maximum Temperature (°C)",
    fill = "Count"
  ) 
print(p1)
```
  Part (ii): Distribution of snowfall values > 0 and < 100, separated by year
```{r Distribution of snowfall values}
p2 = ny_noaa |> 
  filter(snow > 0 & snow < 100) |> 
  ggplot(aes(x = snow, y = as.factor(year))) + 
  geom_density_ridges() +
  labs(
    title = "Distribution of Snowfall (0 < snowfall < 100)",
    x = "Snowfall (tenths of mm)",
    y = "Year"
  )
print(p2)
```

Combination of p1 and p2
```{r Combination of p1 and p2}
library(gridExtra)
grid.arrange(p1, p2, nrow = 1) 
```


# Problem 2
Load data
```{r load data2}
demographic_df = read_csv("./data/nhanes_covar.csv", skip = 4)
accelerometer_df = read_csv("./data/nhanes_accel.csv")
```
tidy the data 
```{r tidy the data for demographic_df}
demographic_df = demographic_df |> 
  janitor::clean_names() |>
  drop_na() |> 
  filter(age >= 21) |> 
  mutate(sex = as.character(sex)) |> 
  mutate(
    sex = case_when(
      sex == "1" ~ "male",
      sex == "2" ~ "female")) |>
  mutate(education = as.character(education)) |> 
  mutate(
    education = case_when(
      education == "1" ~ "less than high school",
      education == "2" ~ "high school equivalent",
      education == "3" ~ "more than high school")) |> 
  mutate(
    education = factor(
      education, 
      levels = c("less than high school", "high school equivalent", "more than high school")))
```

```{r tidy the data for accelerometer_df}
accelerometer_df = accelerometer_df |> 
  janitor::clean_names()
```
merge the data sets
```{r merge the data sets}
merge_df = left_join(demographic_df, accelerometer_df, by = "seqn")
print(merge_df)
```


men and women in each education category
```{r men and women in each education}
gender_education_df = merge_df |> 
  group_by(sex, education) |>
  summarize(count = n()) |> 
  pivot_wider(names_from = education, values_from = count)
print(gender_education_df)
```

age distribution for men and women in different education
```{r age distribution}
hist_distribution = merge_df |>
  ggplot(aes(x = age, fill = sex)) +
  geom_histogram(alpha = 0.5, position = "identity") +
  facet_wrap(~ education) +
  labs(
    title = "Age Distribution by Gender in Each Education Category",
    x = "Age",
    y = "Count",
    fill = "Gender"
  ) 
print(hist_distribution)
```
We could see from this histogram and the table that in this study the people from the "more than high school" education category are the most, and the number of people from the "less than high school" and "high school equivalent" education category are similar. In the "high school equivalent" education level, the number of women are more than men, but in the other two education levels, the number of men and women are similar. The age distribution in the "more than high school" education category is more concentrated in the younger age, and the age distribution in the "less than high school" education category is more concentrated in the older age. The age distribution in the "high school equivalent" education category is concentrated in the extreme young and extreme old age, the distribution in the middle age is pretty much even.

plot total activity against age
```{r total activity calculation and add to merge_df}
start_col = which(names(merge_df) == "min1")
end_col = which(names(merge_df) == "min1440")
numeric_cols_to_sum = names(merge_df)[start_col:end_col]
merge_df$total_activity = rowSums(merge_df[numeric_cols_to_sum])
print(merge_df)
```

```{r plot scatterplot}
scatterplot_total_activity = merge_df |>
  ggplot(aes(x = age, y = total_activity, color = sex)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "loess", se = FALSE) + 
  facet_wrap(~ education) +  
  labs(title = "Total Activities by Age, Gender, and Education Level",
       x = "Age",
       y = "Total Activity",
       color = "Gender") 
print(scatterplot_total_activity)
```
comment: 
From the plot, we could see that the general trends of total activity in all types of population are decreasing with age. However, with age growing, the total activity of people with "less than high school" education level is decreasing faster than the other two education levels. The total activity of people with "more than high school" education level is decreasing slower than the other two education levels. Specifically, there is a peak of total activity in the population with "less than high school" education level at the age of around 60. For the people with "high school equivalent" education level, the increase or peak is at the age of around 40. For the people with "more than high school" education level, the trend is more stable and the peak for women is at the age of around 50, for man is at the age of around 60. For sex, in both "high school equivalent" and "more than high school", the total activity in women is lower than men at the same age. However, in the "less than high school" education level, the women older than 40 have higher total activity than men at the same age. 


24 hours activity time course
```{r 24 hours activity time course}
time_course = merge_df |>
  select(seqn, sex, education, starts_with("min")) |>
  pivot_longer(cols = starts_with("min"), names_to = "minute", values_to = "activity") |>
  mutate(minute = as.numeric(str_remove(minute, "min"))) 
```

```{r plot 24 hours activity time course}
time_course_plot = 
  ggplot(time_course, aes(x = minute, y = activity, color = sex)) +
  geom_line(alpha = 0.6) +
  geom_smooth(method = "loess", se = FALSE, linetype = "dashed") +
  facet_wrap(~ education) +
  labs(title = "24-Hour Activity Time Courses by Education Level",
       x = "Minute of the Day",
       y = "Activity Time",
       color = "Gender")
print(time_course_plot)

```

comment:
We could see from the plot that the highest activity time in a day for different educational level is different, but the lowest activity time for them all are around 4:00-5:00. For the people with "less than high school" education level, the highest activity time is around 10:00-11:00, and the activity time is decreasing after that. For the people with "high school equivalent" education level, the highest activity time is around 8:00-9:00, and the activity time is decreasing after that with a small peak at around 19:00-20:00 for women in this educational type. For the people with "more than high school" education level, the highest activity time is around 8:00-9:00 for men and 20:00-21:00 for women, and the activity time is relatively low between these. In general, the activity time of people with "more than high school" education level is higher than the other two education levels. Although there are difference in the activity time between gender and educational level, the general trend in three panels are similar. The activity time is increasing to peak of the day at 12:00-13:00 and decreasing. Also, the difference between gender is not very significant. Maybe, the women with "less than high school" education level has slightly more activity time than men in this educational level, but the difference is not very significant. In the other two panels, activity time for men is slightly higher than women.


# Problem 3
Import, clean, and tidy these data, and describe the resulting dataset.
```{r load data3}
citi_jan_2020_df = read_csv("./data/citibike/Jan 2020 Citi.csv")
citi_jan_2024_df = read_csv("./data/citibike/Jan 2024 Citi.csv")
citi_july_2020_df = read_csv("./data/citibike/July 2020 Citi.csv")
citi_july_2024_df = read_csv("./data/citibike/July 2024 Citi.csv")
```
check the data frame
```{r check the data frame}
head(citi_jan_2020_df)
head(citi_jan_2024_df)
head(citi_july_2020_df)
head(citi_july_2024_df)
```
check for missing data
```{r check for missing data}
na_counts_jan_2020 = colSums(is.na(citi_jan_2020_df))
na_counts_jan_2024 = colSums(is.na(citi_jan_2024_df))
na_counts_july_2020 = colSums(is.na(citi_july_2020_df))
na_counts_july_2024 = colSums(is.na(citi_july_2024_df))
```
We could find that most missing values are concentrated in the column of "start_station_name" and "end_station_name" in each of the four charts. Because the number of missing data is not very large, we could drop the missing data in these columns.

clean and tidy the data
```{r clean and tidy the data for citi_jan_2020_df}
citi_jan_2020_df = citi_jan_2020_df |> 
  janitor::clean_names() |>
  drop_na(start_station_name, end_station_name) |>
  mutate(year = 2020, month = 1) |> 
  mutate(weekdays = case_when(
    weekdays == "Monday" ~ 1,
    weekdays == "Tuesday" ~ 2,
    weekdays == "Wednesday" ~ 3,
    weekdays == "Thursday" ~ 4,
    weekdays == "Friday" ~ 5,
    weekdays == "Saturday" ~ 6,
    weekdays == "Sunday" ~ 7)) |> 
  filter(duration <= 240) |> 
  select(ride_id, member_casual, year, month, everything())
print(citi_jan_2020_df)
```
```{r clean and tidy the data for citi_jan_2024_df}
citi_jan_2024_df = citi_jan_2024_df |> 
  janitor::clean_names() |>
  drop_na(start_station_name, end_station_name) |>
  mutate(year = 2024, month = 1) |> 
  mutate(weekdays = case_when(
    weekdays == "Monday" ~ 1,
    weekdays == "Tuesday" ~ 2,
    weekdays == "Wednesday" ~ 3,
    weekdays == "Thursday" ~ 4,
    weekdays == "Friday" ~ 5,
    weekdays == "Saturday" ~ 6,
    weekdays == "Sunday" ~ 7)) |> 
  filter(duration <= 240) |> 
  select(ride_id, member_casual, year, month, everything())
print(citi_jan_2024_df)
```
```{r clean and tidy the data for citi_july_2020_df}
citi_july_2020_df = citi_july_2020_df |> 
  janitor::clean_names() |>
  drop_na(start_station_name, end_station_name) |>
  mutate(year = 2020, month = 7) |> 
  mutate(weekdays = case_when(
    weekdays == "Monday" ~ 1,
    weekdays == "Tuesday" ~ 2,
    weekdays == "Wednesday" ~ 3,
    weekdays == "Thursday" ~ 4,
    weekdays == "Friday" ~ 5,
    weekdays == "Saturday" ~ 6,
    weekdays == "Sunday" ~ 7)) |> 
  filter(duration <= 240) |> 
  select(ride_id, member_casual, year, month, everything())
print(citi_july_2020_df)
```
```{r clean and tidy the data for citi_july_2024_df}
citi_july_2024_df = citi_july_2024_df |> 
  janitor::clean_names() |>
  drop_na(start_station_name, end_station_name) |>
  mutate(year = 2024, month = 7) |> 
  mutate(weekdays = case_when(
    weekdays == "Monday" ~ 1,
    weekdays == "Tuesday" ~ 2,
    weekdays == "Wednesday" ~ 3,
    weekdays == "Thursday" ~ 4,
    weekdays == "Friday" ~ 5,
    weekdays == "Saturday" ~ 6,
    weekdays == "Sunday" ~ 7)) |> 
  filter(duration <= 240) |> 
  select(ride_id, member_casual, year, month, everything())
print(citi_july_2024_df)
```
summarize the data

The data frame contains the information of the citibike rides in January and July of 2020 and 2024. The key variables are "ride_id", "member_casual", "year", "month", "rideable_type", "weekdays",  "start_station_name", "end_station_name", "duration". The "ride_id" is a unique identifier for each ride, the "member_casual" is a character variable indicating whether the rider is a member or a casual rider. The "year", "month" and "weekdays" are the year, month and weekday of the ride. The "rideable_type" tells whether the bike people rent is a classic bike or a electric bike. The "start_station_name" and "end_station_name" are the start and end station of the ride. The "duration" is the duration of the ride in minutes. 
All the columns except "year", "month", "weekdays" and "duration" are character variables.
The min, 1st quantile, median, 3rd quantile, max and mean duration in "citi_jan_2020_df" are 1.008, 5.284, 8.866, 15.137, 231.161 and 11.921.
For citi_jan_2024_df, they are 1.002, 4.623, 7.664, 12.964, 225.526, 10.499
For citi_july_2020_df, they are 1.006, 7.966, 14.552, 24.817, 238.780, 18.926
For citi_july_2024_df, they are 1.008, 5.482, 9.593, 16.729, 232.051, 13.402
We could find that in the same year, the average ride time in January is always shorter than that in July. In the same month of different year, the average ride time in 2024 is shorter than that in 2020. 
Also, the number of people who use citybike in July is more than that in January in the same year. In the same month, the number of people who use citybike in 2024 is more than that in 2020.


Produce a reader-friendly table showing the total number of rides in each combination of year and month separating casual riders and Citi Bike members.

First, we need to combine the four data frames into one data frame.
```{r combine the data frames for citibike}
citi_df = bind_rows(citi_jan_2020_df, citi_jan_2024_df, citi_july_2020_df, citi_july_2024_df)
```
Then, we could produce the table.
```{r produce the table}
citi_df |>
  group_by(year, month, member_casual) |>
  summarize(count = n()) |>
  pivot_wider(names_from = member_casual, values_from = count)
```
From the table, we could see that the number of casual and member riders are always bigger in July than in January in the same year, which may be because of the weather. In the same month, the number of member riders is always bigger than the number of casual riders, which may be because of the lower rental rate for member riders. Also, we could see that the user of citibike is increasing from 2020 to 2024, which shows that the citibike is becoming more and more popular.


Make a table showing the 5 most popular starting stations for July 2024; include the number of rides originating from these stations.

```{r the 5 most popular starting stations for July 2024}
citi_july_2024_df |>
  group_by(start_station_name) |>
  summarize(count = n()) |>
  arrange(desc(count)) |>
  head(5)
```
So we could know that the 5 most popular starting stations for July 2024 are above


Make a plot to investigate the effects of day of the week, month, and year on median ride duration. This plot can include one or more panels, but should facilitate comparison across all variables of interest. 

```{r calculate the median ride duration}
p <- citi_df |>
  group_by(year, month, weekdays) |>
  summarize(median_duration = median(duration)) |>
  ggplot(aes(x = weekdays, y = median_duration, color = factor(year))) +
  scale_x_continuous(breaks = 1:7) +
  geom_point() +
  geom_line() +
  facet_wrap(~ month) +
  labs(
    title = "Median Ride Duration by Day of the Week, Month, and Year",
    x = "Weekdays (1 = Monday, 7 = Sunday)",
    y = "Median Ride Duration (minutes)",
    color = "Year"
  )
print(p)
```

From the plot, we could see that the median ride duration is generally longer in 2020 than in 2024 in the same month and the same weekday, which might be because the citibike is less popular in 2020 or because with time going, the perspective of riding a bike is weakened. Also, the median ride duration is longer in July than in January in the same weekday and the same year, which could be because the weather in July is more suitable for biking. Besides, I found that for the trend of median ride duration in a week, there is always a peak at the weekend, on which people have more free time and always a valley on Friday, on which people tend to have a rest after a week's work. The peak and valley are more significant in 2020 than in 2024.



There were relatively few electric Citi Bikes in 2020, but many more are available now. For data in 2024, make a figure that shows the impact of month, membership status, and bike type on the distribution of ride duration.

```{r calculate the distribution of ride duration}
citi_df_2024 = bind_rows(citi_jan_2024_df, citi_july_2024_df)
p1 <- citi_df_2024 |> 
  ggplot(aes(x = duration, fill = member_casual)) +
  geom_histogram(binwidth = 5, position = "dodge", alpha = 0.7) +
  facet_wrap(~ month + rideable_type) +
  labs(
    title = "Impact of Month, Membership Status, and Bike Type on Ride Duration (2024)",
    x = "Ride Duration (minutes)",
    y = "Count",
    fill = "Membership Status"
  )
print(p1)

p2 <- citi_df_2024 |>
  ggplot(aes(x = factor(month), y = duration, fill = member_casual)) +
  geom_boxplot() +
  facet_wrap(~ rideable_type) +
  labs(
    title = "Impact of Month, Membership Status, and Bike Type on Ride Duration (2024)",
    x = "Month",
    y = "Ride Duration (minutes)",
    fill = "Membership Status"
  )
print(p2)


```

We could find from the box plot that the duration time for January and July in 2024 mainly are concentrated in the range of 0-50 minutes but still contain many outliers ranging from 100 to 200, which could explain the extreme right skewed in the histogram. The median duration time for electric bikes is generally shorter than that for classic bikes. The distribution of ride duration for electric bikes is more concentrated than that for classic bikes. 
For histogram, we could see that the frequency of riding electric bikes significantly higher than riding classic bikes in 2024 no matter in January or July and no matter the rider is a member or a casual rider. For membership status, there are more member riders than casual riders in 2024. They both are mainly concentrated between the duration of 0-50 minutes. The distribution of ride duration for member riders is more concentrated than that for casual riders. Also, the distribution of ride duration for member riders is more right skewed than that for casual riders. For month, the distribution of ride duration in July is more right skewed than that in January. The frequency of ride duration in July is more than that in January in general. 
